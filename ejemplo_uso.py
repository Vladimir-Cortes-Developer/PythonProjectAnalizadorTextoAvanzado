def main():
    """
    Ejemplo de uso del analizador de texto con manejo de errores
    """
    print("=" * 60)
    print("EJEMPLO DE USO - ANALIZADOR DE TEXTO AVANZADO")
    print("=" * 60)

    try:
        # Importar el analizador
        from analizador_texto_avanzado import AnalizadorTextoAvanzado
        print("‚úì Analizador importado correctamente")
    except ImportError as e:
        print(f"‚úó Error de importaci√≥n: {e}")
        print("Aseg√∫rate de que el archivo 'analizador_texto_avanzado.py' est√© presente")
        return

    # Crear el analizador
    try:
        analizador = AnalizadorTextoAvanzado()
        print("‚úì Analizador inicializado")
    except Exception as e:
        print(f"‚úó Error inicializando analizador: {e}")
        return

    # Tu texto a analizar
    texto = """
    La inteligencia artificial est√° revolucionando el mundo moderno. 
    Los algoritmos de machine learning permiten a las m√°quinas aprender 
    de grandes vol√∫menes de datos sin ser programadas expl√≠citamente. 
    Esta tecnolog√≠a tiene aplicaciones en medicina, finanzas, educaci√≥n 
    y muchos otros campos importantes. Sin embargo, tambi√©n plantea desaf√≠os √©ticos 
    importantes que debemos considerar cuidadosamente.

    El futuro de la IA depende de c√≥mo desarrollemos estas tecnolog√≠as 
    de manera responsable. Es crucial que mantengamos un equilibrio 
    entre la innovaci√≥n y la protecci√≥n de los derechos humanos.

    Los sistemas de inteligencia artificial pueden procesar informaci√≥n
    a velocidades que superan las capacidades humanas, pero requieren
    supervisi√≥n constante para evitar sesgos y errores. La colaboraci√≥n
    entre humanos y m√°quinas ser√° fundamental para el progreso futuro.

    Esta tecnolog√≠a revolucionaria est√° transformando sectores completos
    y creando nuevas oportunidades de desarrollo profesional y econ√≥mico.
    """

    print(f"Texto preparado ({len(texto)} caracteres)")

    # Realizar an√°lisis completo
    print("\nIniciando an√°lisis completo...")
    try:
        resultados = analizador.analizar_texto_completo(texto)
        print("‚úì An√°lisis completado exitosamente")
    except Exception as e:
        print(f"‚úó Error durante el an√°lisis: {e}")
        return

    # Verificar que tenemos resultados
    if not resultados:
        print("‚úó No se generaron resultados del an√°lisis")
        return

    # Mostrar resultados principales
    print("\n" + "=" * 50)
    print("RESULTADOS DEL AN√ÅLISIS")
    print("=" * 50)

    try:
        # Resumen ejecutivo
        resumen = resultados.get('resumen_ejecutivo', {})
        if resumen:
            print(f"\nRESUMEN EJECUTIVO:")
            print(f"   ‚Ä¢ Palabras totales: {resumen.get('total_palabras', 'N/A')}")
            print(f"   ‚Ä¢ Palabras √∫nicas: {resumen.get('palabras_unicas', 'N/A')}")
            print(f"   ‚Ä¢ Diversidad l√©xica: {resumen.get('diversidad_lexica', 'N/A')}")
            print(f"   ‚Ä¢ Sentimiento: {resumen.get('sentimiento_general', 'N/A')}")
            print(f"   ‚Ä¢ Complejidad: {resumen.get('complejidad', 'N/A')}")

            temas = resumen.get('temas_principales', [])
            if temas:
                print(f"   ‚Ä¢ Temas principales: {', '.join(temas)}")
        else:
            print("‚ö† No se encontr√≥ resumen ejecutivo")

        # Top 10 palabras m√°s frecuentes
        frecuencias = resultados.get('frecuencias', {})
        mas_frecuentes = frecuencias.get('mas_frecuentes', [])
        if mas_frecuentes:
            print(f"\nTOP 10 PALABRAS M√ÅS FRECUENTES:")
            for i, (palabra, freq) in enumerate(mas_frecuentes[:10], 1):
                print(f"   {i:2d}. {palabra:<15} ({freq} veces)")
        else:
            print("‚ö† No se encontraron palabras frecuentes")

        # Bigramas importantes
        bigramas = resultados.get('bigramas', [])
        if bigramas:
            print(f"\nBIGRAMAS M√ÅS COMUNES:")
            for i, (bigrama, freq) in enumerate(bigramas[:5], 1):
                print(f"   {i}. '{' '.join(bigrama)}' ({freq} veces)")
        else:
            print("‚ö† No se encontraron bigramas")

        # Mostrar an√°lisis de sentimientos detallado
        sentimientos = resultados.get('sentimientos', {})
        if sentimientos:
            print(f"\nAN√ÅLISIS DE SENTIMIENTOS:")
            if 'textblob' in sentimientos:
                sent = sentimientos['textblob']
                print(f"   ‚Ä¢ TextBlob - Polaridad: {sent.get('polaridad', 'N/A')} ({sent.get('clasificacion', 'N/A')})")
                print(f"   ‚Ä¢ TextBlob - Subjetividad: {sent.get('subjetividad', 'N/A')}")

            if 'vader' in sentimientos:
                vader = sentimientos['vader']
                print(f"   ‚Ä¢ VADER - Compuesto: {vader.get('compuesto', 'N/A')} ({vader.get('clasificacion', 'N/A')})")
                print(f"   ‚Ä¢ VADER - Positivo: {vader.get('positivo', 'N/A')}")
                print(f"   ‚Ä¢ VADER - Neutral: {vader.get('neutral', 'N/A')}")
                print(f"   ‚Ä¢ VADER - Negativo: {vader.get('negativo', 'N/A')}")

            if not sentimientos.get('textblob') and not sentimientos.get('vader'):
                print("   ‚ö† An√°lisis de sentimientos no disponible")

        # Mostrar m√©tricas de legibilidad
        legibilidad = resultados.get('legibilidad', {})
        if legibilidad and 'error' not in legibilidad:
            print(f"\nM√âTRICAS DE LEGIBILIDAD:")
            print(f"   ‚Ä¢ Oraciones: {legibilidad.get('oraciones', 'N/A')}")
            print(f"   ‚Ä¢ Palabras por oraci√≥n: {legibilidad.get('palabras_por_oracion', 'N/A')}")
            print(f"   ‚Ä¢ Caracteres por palabra: {legibilidad.get('caracteres_por_palabra', 'N/A')}")
            print(f"   ‚Ä¢ √çndice de complejidad: {legibilidad.get('indice_complejidad', 'N/A')}")
            print(f"   ‚Ä¢ Nivel de dificultad: {legibilidad.get('nivel_dificultad', 'N/A')}")
        else:
            print("‚ö† M√©tricas de legibilidad no disponibles")

        # Mostrar informaci√≥n de entidades (si est√°n disponibles)
        entidades = resultados.get('entidades', {})
        if entidades and 'error' not in entidades:
            resumen_ent = entidades.get('resumen', {})
            if resumen_ent:
                print(f"\nENTIDADES ENCONTRADAS:")
                for tipo, cantidad in resumen_ent.items():
                    print(f"   ‚Ä¢ {tipo}: {cantidad}")
            else:
                print("   ‚Ä¢ No se encontraron entidades nombradas")
        else:
            print("‚ö† Extracci√≥n de entidades no disponible (requiere spaCy)")

    except Exception as e:
        print(f"‚úó Error mostrando resultados: {e}")

    # Generar visualizaciones
    print(f"\n" + "=" * 50)
    print("GENERANDO VISUALIZACIONES Y REPORTES")
    print("=" * 50)

    try:
        print("Generando visualizaciones...")
        analizador.generar_visualizaciones(guardar=True)
        print("‚úì Visualizaciones generadas exitosamente")
    except Exception as e:
        print(f"‚ö† Error generando visualizaciones: {e}")
        print("Las visualizaciones pueden requerir dependencias adicionales")

    # Generar reportes
    reportes_generados = []

    try:
        print("Generando reporte HTML...")
        reporte_html = analizador.generar_reporte_completo(formato='html')
        if reporte_html:
            reportes_generados.append(reporte_html)
            print(f"‚úì Reporte HTML: {reporte_html}")
    except Exception as e:
        print(f"‚ö† Error generando reporte HTML: {e}")

    try:
        print("Generando reporte JSON...")
        reporte_json = analizador.generar_reporte_completo(formato='json')
        if reporte_json:
            reportes_generados.append(reporte_json)
            print(f"‚úì Reporte JSON: {reporte_json}")
    except Exception as e:
        print(f"‚ö† Error generando reporte JSON: {e}")

    try:
        print("Generando reporte TXT...")
        reporte_txt = analizador.generar_reporte_completo(formato='txt')
        if reporte_txt:
            reportes_generados.append(reporte_txt)
            print(f"‚úì Reporte TXT: {reporte_txt}")
    except Exception as e:
        print(f"‚ö† Error generando reporte TXT: {e}")

    # Resumen final
    print(f"\n" + "=" * 50)
    print("AN√ÅLISIS COMPLETADO")
    print("=" * 50)

    if reportes_generados:
        print(f"‚úì Se generaron {len(reportes_generados)} reportes:")
        for reporte in reportes_generados:
            print(f"   - {reporte}")
    else:
        print("‚ö† No se generaron reportes")

    # Verificar archivos adicionales
    import os
    archivos_adicionales = ['dashboard_analisis_texto.html', 'nube_palabras.png']
    archivos_encontrados = []

    for archivo in archivos_adicionales:
        if os.path.exists(archivo):
            archivos_encontrados.append(archivo)

    if archivos_encontrados:
        print(f"\nArchivos adicionales generados:")
        for archivo in archivos_encontrados:
            print(f"   - {archivo}")

    print(f"\nüéâ ¬°An√°lisis completado exitosamente!")
    print(f"Revisa los archivos generados para ver los resultados detallados.")


def probar_funcionalidades_basicas():
    """
    Prueba las funcionalidades b√°sicas sin generar archivos
    """
    print("\n" + "=" * 60)
    print("PRUEBA R√ÅPIDA DE FUNCIONALIDADES B√ÅSICAS")
    print("=" * 60)

    try:
        from analizador_texto_avanzado import AnalizadorTextoAvanzado

        analizador = AnalizadorTextoAvanzado()

        texto_prueba = """
        Este es un texto de prueba para verificar que el analizador funciona correctamente.
        Contiene diferentes tipos de palabras y estructuras para evaluar las capacidades
        del sistema de an√°lisis de texto avanzado.
        """

        print("Ejecutando an√°lisis b√°sico...")
        resultados = analizador.analizar_texto_completo(texto_prueba)

        if resultados:
            resumen = resultados.get('resumen_ejecutivo', {})
            print(f"‚úì Palabras analizadas: {resumen.get('total_palabras', 0)}")
            print(f"‚úì Diversidad l√©xica: {resumen.get('diversidad_lexica', 0):.4f}")
            print(f"‚úì Sentimiento detectado: {resumen.get('sentimiento_general', 'N/A')}")
            print(f"‚úì An√°lisis completado correctamente")
            return True
        else:
            print("‚úó No se generaron resultados")
            return False

    except Exception as e:
        print(f"‚úó Error en prueba b√°sica: {e}")
        return False


def verificar_dependencias():
    """
    Verifica que las dependencias est√©n disponibles
    """
    print("\n" + "=" * 60)
    print("VERIFICACI√ìN DE DEPENDENCIAS")
    print("=" * 60)

    dependencias = [
        ('nltk', 'Natural Language Toolkit'),
        ('pandas', 'Data Analysis'),
        ('numpy', 'Numerical Computing'),
        ('matplotlib', 'Plotting'),
        ('seaborn', 'Statistical Visualization'),
        ('wordcloud', 'Word Cloud Generation'),
        ('plotly', 'Interactive Plotting'),
        ('textblob', 'Text Processing'),
    ]

    dependencias_disponibles = 0
    total_dependencias = len(dependencias)

    for modulo, descripcion in dependencias:
        try:
            __import__(modulo)
            print(f"‚úì {modulo:<12} - {descripcion}")
            dependencias_disponibles += 1
        except ImportError:
            print(f"‚úó {modulo:<12} - NO INSTALADO - {descripcion}")

    # Verificar spaCy por separado
    try:
        import spacy
        print(f"‚úì {'spacy':<12} - Advanced NLP")
        dependencias_disponibles += 0.5

        try:
            nlp = spacy.load("es_core_news_sm")
            print(f"‚úì {'es_core_news_sm':<12} - Spanish Model")
            dependencias_disponibles += 0.5
        except OSError:
            print(f"‚ö† {'es_core_news_sm':<12} - MODELO NO INSTALADO")
            print("  Instala con: python -m spacy download es_core_news_sm")
    except ImportError:
        print(f"‚úó {'spacy':<12} - NO INSTALADO - Advanced NLP")

    # Verificar VADER
    try:
        from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
        print(f"‚úì {'vaderSentiment':<12} - Sentiment Analysis")
        dependencias_disponibles += 1
    except ImportError:
        print(f"‚úó {'vaderSentiment':<12} - NO INSTALADO - pip install vaderSentiment")

    porcentaje = (dependencias_disponibles / (total_dependencias + 2)) * 100
    print(f"\nDependencias disponibles: {dependencias_disponibles}/{total_dependencias + 2} ({porcentaje:.1f}%)")

    if porcentaje >= 90:
        print("üéâ Todas las dependencias principales est√°n disponibles")
    elif porcentaje >= 70:
        print("‚ö† La mayor√≠a de dependencias est√°n disponibles - funcionalidad limitada")
    else:
        print("‚ùå Muchas dependencias faltan - se requiere instalaci√≥n")

    return porcentaje >= 70


if __name__ == "__main__":
    try:
        # Verificar dependencias primero
        deps_ok = verificar_dependencias()

        # Prueba b√°sica
        if deps_ok:
            prueba_ok = probar_funcionalidades_basicas()

            if prueba_ok:
                # Ejecutar ejemplo completo
                main()
            else:
                print("\n‚ùå La prueba b√°sica fall√≥ - revisa la configuraci√≥n")
        else:
            print("\n‚ùå Faltan dependencias cr√≠ticas")
            print("Instala las dependencias con:")
            print("pip install nltk pandas numpy matplotlib seaborn wordcloud plotly textblob spacy vaderSentiment")
            print("python -m spacy download es_core_news_sm")

    except KeyboardInterrupt:
        print("\n\nEjecuci√≥n cancelada por el usuario")
    except Exception as e:
        print(f"\n\nError inesperado: {e}")
        print("Por favor, verifica que todos los archivos est√©n presentes y las dependencias instaladas")